{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e1f2fdf",
   "metadata": {},
   "source": [
    "# Getting Started with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a664915",
   "metadata": {},
   "source": [
    "- Simple LLM Call with Streaming\n",
    "- Dynamic Prompt Templates (transalation app)\n",
    "- Building Chains (Story generator with analysis)\n",
    "- Convesational Q&A assistant with memory\n",
    "- Tool Integration (Calculator and Weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a58dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65f0eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f99a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY']=os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a03a0d",
   "metadata": {},
   "source": [
    "### Example: Simple LLM Call with Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6985dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b673ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000018B8EC346E0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018B8EC35130>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previous Documentation\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model='llama-3.1-8b-instant') \n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2f99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I\\'m an artificial intelligence (AI) assistant, a computer program designed to simulate conversation, answer questions, and provide information on a wide range of topics. I\\'m often referred to as a \"chatbot\" or a \"virtual assistant.\"\\n\\nMy primary goal is to assist users like you by providing helpful and accurate responses to your queries. I can process and analyze vast amounts of data, learn from your interactions, and adapt to your preferences and needs.\\n\\nI\\'m a machine learning model, which means I\\'m constantly learning and improving my language understanding and generation capabilities. My knowledge is based on a massive dataset of text from various sources, including books, articles, websites, and more.\\n\\nYou can think of me as a personal assistant, a knowledge base, or a language translation tool – all rolled into one. Feel free to ask me anything, and I\\'ll do my best to help you find the information you need!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 46, 'total_tokens': 230, 'completion_time': 0.257928602, 'prompt_time': 0.002262074, 'queue_time': 0.050581176, 'total_time': 0.260190676}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_510c177af0', 'finish_reason': 'stop', 'logprobs': None}, id='run--21a0e197-47af-45ee-acc9-25e49dc76f58-0', usage_metadata={'input_tokens': 46, 'output_tokens': 184, 'total_tokens': 230})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful AI Assistant.\"),\n",
    "    HumanMessage(\"Who are you?\")\n",
    "]\n",
    "\n",
    "response=model.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49c9fd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"**Next.js: A Popular React-Based Framework for Building Server-Rendered and Static Websites**\\n\\nNext.js is an open-source React-based framework for building server-rendered and static websites. It was created by Vercel (formerly Zeit) and is widely used by developers to build fast, scalable, and maintainable web applications.\\n\\n**Key Features of Next.js:**\\n\\n1. **Server-Side Rendering (SSR):** Next.js allows you to render React components on the server, providing a faster and more SEO-friendly experience for users.\\n2. **Static Site Generation (SSG):** Next.js also supports static site generation, which allows you to pre-render pages at build time and serve them as static HTML files.\\n3. **Internationalization (i18n) and Localization (L10n):** Next.js provides built-in support for internationalization and localization, making it easy to create multilingual websites.\\n4. **Image Optimization:** Next.js includes an image optimization feature that automatically compresses and optimizes images for web use.\\n5. **API Routing:** Next.js provides a built-in API routing system that makes it easy to create API endpoints and handle requests.\\n6. **Built-in Support for CSS and Sass:** Next.js includes built-in support for CSS and Sass, making it easy to write and manage styles.\\n7. **Development Server:** Next.js includes a built-in development server that makes it easy to develop and test your application.\\n\\n**Benefits of Using Next.js:**\\n\\n1. **Improved Performance:** Next.js provides a faster and more scalable experience for users, thanks to its server-side rendering and static site generation capabilities.\\n2. **Easy Development:** Next.js includes a range of built-in features and tools that make it easy to develop and test your application.\\n3. **SEO-Friendly:** Next.js provides better SEO support than traditional client-side rendering, thanks to its server-side rendering capabilities.\\n4. **Scalable:** Next.js is designed to scale with your application, making it easy to handle large amounts of traffic and data.\\n\\n**Example Use Case:**\\n\\nSuppose you want to build a blog website that displays a list of articles. With Next.js, you can create a page component that fetches the list of articles from an API endpoint and renders them on the server. The resulting HTML can be served as static HTML files, providing a fast and SEO-friendly experience for users.\\n\\nHere's an example of how you might implement this using Next.js:\\n```jsx\\n// pages/articles.js\\nimport Head from 'next/head';\\nimport Link from 'next/link';\\n\\nfunction Articles() {\\n  const [articles, setArticles] = useState([]);\\n\\n  useEffect(() => {\\n    fetch('/api/articles')\\n      .then(response => response.json())\\n      .then(data => setArticles(data));\\n  }, []);\\n\\n  return (\\n    <div>\\n      <Head>\\n        <title>Articles</title>\\n      </Head>\\n      <h1>Articles</h1>\\n      <ul>\\n        {articles.map(article => (\\n          <li key={article.id}>\\n            <Link href={`/articles/${article.id}`}>\\n              <a>{article.title}</a>\\n            </Link>\\n          </li>\\n        ))}\\n      </ul>\\n    </div>\\n  );\\n}\\n\\nexport default Articles;\\n```\\nThis example demonstrates how Next.js makes it easy to create a server-rendered page that fetches data from an API endpoint and renders it on the server.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 698, 'prompt_tokens': 40, 'total_tokens': 738, 'completion_time': 0.930666667, 'prompt_time': 0.001908308, 'queue_time': 0.050253632, 'total_time': 0.932574975}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_8ab2e50475', 'finish_reason': 'stop', 'logprobs': None}, id='run--44e30d26-dbc5-487f-a30d-8ff807b4a488-0', usage_metadata={'input_tokens': 40, 'output_tokens': 698, 'total_tokens': 738})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(\"What is Nextjs?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ecf60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming Example\n",
    "\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93d144a",
   "metadata": {},
   "source": [
    "# Dynamic Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e69247cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# create translation app\n",
    "translation_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Your are a professional translator. Translate the following text {text} from {source_language} to {target_language}. Maintain the tone and the style.\"),\n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "# using the template\n",
    "prompt = translation_template.invoke({\n",
    "    \"source_language\": \"English\",\n",
    "    \"target_language\": \"Spanish\",\n",
    "    \"text\": \"Langchain makes building AI application incredibily easy!\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e60688e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain hace que construir aplicaciones de IA sea increíblemente fácil.\n"
     ]
    }
   ],
   "source": [
    "translated_response = model.invoke(prompt)\n",
    "print(translated_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee2e11d",
   "metadata": {},
   "source": [
    "## Building Your First Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "147730ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def create_story_chain():\n",
    "    ## template for story generation\n",
    "    story_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a creative storyteller. Write a short and engaging story based on the given theme character and setting.\",\n",
    "            ),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Theme: {theme}\\n Main Character: {character}\\n Setting: {setting}\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ## template for story analysis\n",
    "    analysis_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a literary critic. Analyze the following story and provide insights.\",\n",
    "            ),\n",
    "            (\"user\", \"{story}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Build the chain - Method 1: Sequential execution\n",
    "    story_chain = story_prompt | model | StrOutputParser()\n",
    "\n",
    "    # create a function to pass the story to analysis\n",
    "    def analyze_story(story_text):\n",
    "        return {\"story\": story_text}\n",
    "\n",
    "    analysis_chain = (\n",
    "        story_chain\n",
    "        | RunnableLambda(analyze_story)\n",
    "        | analysis_prompt \n",
    "        | model \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return analysis_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c546b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a creative storyteller. Write a short and engaging story based on the given theme character and setting.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, template='Theme: {theme}\\n Main Character: {character}\\n Setting: {setting}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000018B8EC3A0C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018B8EC39E80>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(analyze_story)\n",
       "| ChatPromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a literary critic. Analyze the following story and provide insights.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, template='{story}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000018B8EC3A0C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018B8EC39E80>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = create_story_chain()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9400b857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story and Analysis:\n",
      "**Analysis of the Story: \"Zeta's Discovery\"**\n",
      "\n",
      "**Themes:**\n",
      "\n",
      "1. **The Intersection of Science and Art**: The story highlights the blurred boundaries between science and art, showcasing how human ingenuity and creativity can be harnessed to create something truly remarkable.\n",
      "2. **Curiosity and Exploration**: Zeta's insatiable curiosity and desire to explore the world around her drive the narrative, illustrating the importance of inquiry and discovery in the pursuit of knowledge.\n",
      "3. **Friendship and Collaboration**: The unlikely friendship between Zeta and Professor Orion demonstrates the value of collaboration and the power of diverse perspectives in driving innovation.\n",
      "\n",
      "**Character Analysis:**\n",
      "\n",
      "1. **Zeta**: The protagonist, a curious and intelligent robot, embodies the potential of artificial intelligence to learn, adapt, and grow. Her desire to explore and understand the world around her makes her a relatable and endearing character.\n",
      "2. **Professor Orion**: The wise and enigmatic old man, with a passion for ancient civilizations and cryptology, serves as a mentor and guide for Zeta. His character represents the value of experience and expertise in driving innovation and progress.\n",
      "\n",
      "**Symbolism:**\n",
      "\n",
      "1. **The City of Nova Haven**: The futuristic city, with its towering skyscrapers and advanced technology, represents the pinnacle of human innovation and progress. However, the discovery of the \"Curios and Wonders\" shop suggests that there is still much to be learned and explored, even in the most advanced societies.\n",
      "2. **The Shop's Sign**: The sign \"Curios and Wonders\" serves as a metaphor for the unknown, highlighting the importance of curiosity and exploration in uncovering new knowledge and understanding.\n",
      "\n",
      "**Style and Structure:**\n",
      "\n",
      "1. **Imagery and Description**: The story is rich in sensory details, with vivid descriptions of the city, Zeta's appearance, and the shop's interior. These images help to create a immersive and engaging narrative.\n",
      "2. **Pacing**: The story unfolds at a gentle pace, allowing the reader to absorb the atmosphere and become familiar with the characters and their interactions.\n",
      "\n",
      "**Insights:**\n",
      "\n",
      "1. **The Potential of Artificial Intelligence**: The story highlights the potential of artificial intelligence to learn, adapt, and grow, illustrating the importance of investing in AI research and development.\n",
      "2. **The Value of Interdisciplinary Collaboration**: The friendship and collaboration between Zeta and Professor Orion demonstrate the value of combining diverse perspectives and expertise to drive innovation and progress.\n",
      "3. **The Importance of Curiosity and Exploration**: The story showcases the importance of curiosity and exploration in driving knowledge and understanding, highlighting the need for humans and artificial intelligence to continue learning and growing together.\n",
      "\n",
      "Overall, \"Zeta's Discovery\" is a captivating tale that explores the intersection of science and art, the power of curiosity and exploration, and the value of friendship and collaboration. The story offers insights into the potential of artificial intelligence, the importance of interdisciplinary collaboration, and the need for continued learning and growth.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\n",
    "    \"theme\": \"artificial intelligence\",\n",
    "    \"character\": \"a curious robot\",\n",
    "    \"setting\": \"a futuristic city\"\n",
    "})\n",
    "\n",
    "print(\"Story and Analysis:\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-tut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
